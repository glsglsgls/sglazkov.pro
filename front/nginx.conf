user nginx;
worker_processes auto;
pcre_jit on;
pid /tmp/nginx.pid;
error_log /dev/stdout info;
worker_rlimit_nofile 100000;

events {
    worker_connections 4000;
    use epoll;
    multi_accept on;
    accept_mutex on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    access_log /dev/stdout;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for"';
    # cache informations about FDs, frequently accessed files
    # can boost performance, but you need to test those values
    open_file_cache max=20000 inactive=12h;
    open_file_cache_valid 30m;
    open_file_cache_errors on;

    # copies data between one FD and other from within the kernel
    # faster than read() + write()
    sendfile on;
    # send headers in one piece, it is better than sending them one by one
    tcp_nopush on;
    # don't buffer data sent, good for small data bursts in real time
    tcp_nodelay on;
    # allow the server to close connection on non responding client, this will free up memory
    reset_timedout_connection on;
    # request timed out -- default 60
    client_body_timeout 10;
    # if client stop responding, free up memory -- default 60
    # send_timeout 2;
    # server will close connection after this time -- default 75
    # keepalive_timeout 30;
    # number of requests client can make over keep-alive -- for testing environment
    keepalive_requests 100000;
    client_max_body_size 1m;
    server_tokens  off;

    server {
        listen 80;
        listen [::]:80;
        server_name sglazkov.pro;
        set $web_root /srv/www/;

        location / {
            etag on;
            expires 30d;
            add_header Cache-Control public;
            access_log off;
            add_header Access-Control-Allow-Origin *;
            root $web_root;
            try_files $uri $uri/index.html =404;
            index index.html;
        }
    }
}
